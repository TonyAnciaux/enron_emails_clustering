{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afb2500e-530f-4791-86a3-b4ae18b3613f",
   "metadata": {},
   "source": [
    "# Lemmatization of the mails\n",
    "This notebook contains the code necessary to lemmatize the emails and collect the tokens in a single datastructur (here a set to avoid duplicates). The work is divided in four in order to speed the process.\n",
    "\n",
    "I assume that you have already downloaded and extracted the dataset. For instance, you should have, in the repository of the project, the folder `data` inside which there is a folder called `maildir`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b417ce92-ef86-41d9-afb6-6b997ed82a43",
   "metadata": {},
   "source": [
    "## Removing duplicates\n",
    "This bit of code removes duplicate messages. You may ignore it. Go to the next step **Path selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d7a8839-3639-4579-9623-7e6ed8f29be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26a4d8dc-e951-4aff-b7ab-f983f92234cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mails.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "516fa95d-c36a-42a4-8de0-44012ae32c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>message</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your News Alert for QCOM</td>\n",
       "      <td>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=...</td>\n",
       "      <td>./maildir/lewis-a/all_documents/119.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Incredible low fares, wherever you're traveling!</td>\n",
       "      <td>[IMAGE]\\n\\n=09homeflightshotelscarspackagescru...</td>\n",
       "      <td>./maildir/lewis-a/all_documents/186.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClickAtHome Pilot 2 Program - An Invitation</td>\n",
       "      <td>---------------------- Forwarded by Suzanne Br...</td>\n",
       "      <td>./maildir/lewis-a/all_documents/155.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Your News Alert for YHOO</td>\n",
       "      <td>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=...</td>\n",
       "      <td>./maildir/lewis-a/all_documents/38.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Improved Process for Engaging Temporary Workers</td>\n",
       "      <td>As you are aware, Enron utilizes temporary sta...</td>\n",
       "      <td>./maildir/lewis-a/all_documents/54.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517396</th>\n",
       "      <td>Weekly EOTT Update - Meeting 10/11/200</td>\n",
       "      <td>As Reported by David Hultsman of EOTT:\\n\\nWe b...</td>\n",
       "      <td>./maildir/beck-s/eott/2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517397</th>\n",
       "      <td>&lt;&lt;Concur Expense Document&gt;&gt; - Brent Price</td>\n",
       "      <td>The following expense report is ready for appr...</td>\n",
       "      <td>./maildir/beck-s/expense_reports/1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517398</th>\n",
       "      <td>&lt;&lt;Concur Expense Document&gt;&gt; - Brent Price</td>\n",
       "      <td>The following expense report is ready for appr...</td>\n",
       "      <td>./maildir/beck-s/expense_reports/2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517399</th>\n",
       "      <td>Texas Unfinaled Invoices - May 2000 Production</td>\n",
       "      <td>FYI.\\n---------------------- Forwarded by Bren...</td>\n",
       "      <td>./maildir/beck-s/unfinaled_invoices/1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517400</th>\n",
       "      <td>Unfinalized Invoices</td>\n",
       "      <td>FYI...Susan sent this memo to all gas function...</td>\n",
       "      <td>./maildir/beck-s/unfinaled_invoices/2.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517401 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Subject  \\\n",
       "0                               Your News Alert for QCOM   \n",
       "1       Incredible low fares, wherever you're traveling!   \n",
       "2            ClickAtHome Pilot 2 Program - An Invitation   \n",
       "3                               Your News Alert for YHOO   \n",
       "4        Improved Process for Engaging Temporary Workers   \n",
       "...                                                  ...   \n",
       "517396            Weekly EOTT Update - Meeting 10/11/200   \n",
       "517397         <<Concur Expense Document>> - Brent Price   \n",
       "517398         <<Concur Expense Document>> - Brent Price   \n",
       "517399    Texas Unfinaled Invoices - May 2000 Production   \n",
       "517400                              Unfinalized Invoices   \n",
       "\n",
       "                                                  message  \\\n",
       "0       =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=...   \n",
       "1       [IMAGE]\\n\\n=09homeflightshotelscarspackagescru...   \n",
       "2       ---------------------- Forwarded by Suzanne Br...   \n",
       "3       =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=...   \n",
       "4       As you are aware, Enron utilizes temporary sta...   \n",
       "...                                                   ...   \n",
       "517396  As Reported by David Hultsman of EOTT:\\n\\nWe b...   \n",
       "517397  The following expense report is ready for appr...   \n",
       "517398  The following expense report is ready for appr...   \n",
       "517399  FYI.\\n---------------------- Forwarded by Bren...   \n",
       "517400  FYI...Susan sent this memo to all gas function...   \n",
       "\n",
       "                                          path  \n",
       "0         ./maildir/lewis-a/all_documents/119.  \n",
       "1         ./maildir/lewis-a/all_documents/186.  \n",
       "2         ./maildir/lewis-a/all_documents/155.  \n",
       "3          ./maildir/lewis-a/all_documents/38.  \n",
       "4          ./maildir/lewis-a/all_documents/54.  \n",
       "...                                        ...  \n",
       "517396                ./maildir/beck-s/eott/2.  \n",
       "517397     ./maildir/beck-s/expense_reports/1.  \n",
       "517398     ./maildir/beck-s/expense_reports/2.  \n",
       "517399  ./maildir/beck-s/unfinaled_invoices/1.  \n",
       "517400  ./maildir/beck-s/unfinaled_invoices/2.  \n",
       "\n",
       "[517401 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85638432-f0af-497e-a23b-0781411bec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=[\"Subject\", \"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ec8ea4c-d1b5-4c29-9c8b-72e8d314a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9af4a7b7-bb5d-4de3-8b85-2e272bb6a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"paths.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f699f89-934e-4775-add3-bfb5f3fabf3a",
   "metadata": {},
   "source": [
    "## Paths selection\n",
    "This is the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "13f72cf3-3552-49c5-89cb-aa6b10d83275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "887f6dd8-c6fc-4e40-9fae-b514edd6c3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paths = pd.read_csv(\"paths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0250e01a-3de5-4068-9d06-71ca89786f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = int(df_paths.shape[0]/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6d7ea3-2f54-41d9-af9d-eb12d93801cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cc42b690-6792-4b10-8c06-001696ac55b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62563\n"
     ]
    }
   ],
   "source": [
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b26546-e90b-41ac-ae33-ef1173865eda",
   "metadata": {},
   "source": [
    "Uncomment the following line of code according to your name. This will give you a list of paths for the emails you need to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ec1ba5cd-c282-40d6-af5e-b5e7603e44f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TONY\n",
    "#paths = df.iloc[:l].to_list()\n",
    "## BINIAM\n",
    "#paths = df.iloc[(l+1):2*l].to_list()\n",
    "## GIOVANNA\n",
    "#paths = df.iloc[(2*l+1):3*l].to_list()\n",
    "## QUENTIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7dac0e-30f9-4f53-ae38-a43845b857a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6ea4356b-1ed2-4987-8c62-75565fd0da9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62562"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8021e826-6aad-45f5-8042-9381c31f6c23",
   "metadata": {},
   "source": [
    "## Lemmas collection\n",
    "Some of the code comes from what we did today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "70bf98c8-94e4-45a9-9769-e3011a9cca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import spacy\n",
    "import csv\n",
    "import email\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2e8beb70-487b-4753-b2cd-eb686ef74319",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def token_of_email(email):\n",
    "    lemmas = nlp(email)\n",
    "    # add NER\n",
    "    return [w.lemma_ for w in lemmas if not w.lemma_.lower() in stop_words and w.lemma_.isalpha()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7205d261-7768-4660-9451-b41b4188ff56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c34656e0-6fe5-48ec-b950-3d91d7618b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f261d6d7-fb63-4d84-95ee-de7eec78ee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for path in paths:\n",
    "    with open(path, \"r\", encoding=\"windows-1252\") as file:\n",
    "         sample = email.message_from_file(file)\n",
    "    message = sample._payload\n",
    "    lemmas = set(token_of_email(message))\n",
    "    dictionary.update(lemmas)\n",
    "    i +=1\n",
    "    print(f\"len set is {len(dictionary)} and we're at ireteration no {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63b87a0-9f3c-4eaf-8ac5-5059f5dddffc",
   "metadata": {},
   "source": [
    "## Pickle the bits!\n",
    "Or how to save an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0c3b1f9e-c523-42b0-9ada-9d825deecb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3113a9-f024-436d-a921-976fec03101a",
   "metadata": {},
   "source": [
    "Please replace quentin by your name^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "61806bb1-ee59-4f4a-9627-578de6635cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickled_dict_quentin\", \"ab\") as pick:\n",
    "    pickle.dump(dictionary, pick) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056dc360-74b7-44af-9887-b86c4d95fc19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
