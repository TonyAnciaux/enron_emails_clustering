{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import spacy\n",
    "import csv\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data and \n",
    "df = pd.read_csv(\"enron_email.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/giods/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/giods/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this needs to run if we are using NLTK for the first time\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11        \\n\\n\\n---------------------- Forwarded by Yola...\n",
       "32        Jim --\\n\\nPlease see attached from EPSA on the...\n",
       "64        Since I am Chairman of the NERC Interchange Su...\n",
       "66        fyi\\n---------------------- Forwarded by Linda...\n",
       "81        This document, although lengthy, contains insi...\n",
       "                                ...                        \n",
       "517386    Please respond to The Motley Fool \\n==========...\n",
       "517389    Please respond to The Motley Fool \\n==========...\n",
       "517391    Please respond to The Motley Fool \\n==========...\n",
       "517392    Please respond to The Motley Fool \\n==========...\n",
       "517398    \\n=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3...\n",
       "Name: message, Length: 97360, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove from str in df\n",
    "#https://www.kaggle.com/code/oalvay/enron-emails-complete-preprocessing/notebook\n",
    "\n",
    "df.loc[df[\"message\"].str.contains(\"-------------\"), \"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the **message** column in a variable\n",
    "messages = df[\"message\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['message'].map(lambda x: re.sub('[\"http\"|\"html\"|\"click\"|\"url\"]','', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find tokens, lemmatize \n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def token_of_email(email):\n",
    "    lemmas = nlp(email)\n",
    "    # add NER\n",
    "    return [w.lemma_ for w in lemmas if not w.lemma_.lower() in stop_words and w.lemma_.isalpha()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample = nlp(df[\"message\"].iloc[0])\n",
    "#token_of_email(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"token\"] = df['message'].map(token_of_email) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "field larger than field limit (131072)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/home/giods/in-progress/enron_emails_clustering/data/pre_process.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/giods/in-progress/enron_emails_clustering/data/pre_process.ipynb#ch0000009vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39menron_email.csv\u001b[39m\u001b[39m\"\u001b[39m, newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/giods/in-progress/enron_emails_clustering/data/pre_process.ipynb#ch0000009vscode-remote?line=2'>3</a>\u001b[0m     reader\u001b[39m=\u001b[39mcsv\u001b[39m.\u001b[39mreader(file,delimiter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/giods/in-progress/enron_emails_clustering/data/pre_process.ipynb#ch0000009vscode-remote?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m email \u001b[39min\u001b[39;00m reader:\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/giods/in-progress/enron_emails_clustering/data/pre_process.ipynb#ch0000009vscode-remote?line=4'>5</a>\u001b[0m         message \u001b[39m=\u001b[39m email[\u001b[39m2\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/giods/in-progress/enron_emails_clustering/data/pre_process.ipynb#ch0000009vscode-remote?line=5'>6</a>\u001b[0m         lemmas \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(token_of_email(message))\n",
      "\u001b[0;31mError\u001b[0m: field larger than field limit (131072)"
     ]
    }
   ],
   "source": [
    "# dictionary = set()\n",
    "# with open(\"enron_email.csv\", newline=\"\") as file:\n",
    "#     reader=csv.reader(file,delimiter=\",\")\n",
    "#     for email in reader:\n",
    "#         message = email[2]\n",
    "#         lemmas = set(token_of_email(message))\n",
    "#         dictionary.union(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import email\n",
    "dictionary = set()\n",
    "for subdir, dirs, mails in os.walk(\"./maildir\"):\n",
    "    for mail in mails:\n",
    "        path = os.path.join(subdir, mail)\n",
    "        with open(path, \"r\", encoding=\"windows-1252\") as file:\n",
    "            sample = email.message_from_file(file)\n",
    "        message = sample._payload\n",
    "        lemmas = set(token_of_email(message))\n",
    "        dictionary.union(lemmas)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0db4365f837a7f3dbe2e1d1aa541185f47ba353260c2b18bc4c83605f5af4b47"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('nlpenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
